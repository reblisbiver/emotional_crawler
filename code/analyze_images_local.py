"""
æœ¬åœ°å›¾ç‰‡æƒ…ç»ªåˆ†æè„šæœ¬
éœ€è¦å®‰è£…: pip install fer opencv-python tensorflow

ä½¿ç”¨æ–¹æ³•ï¼š
python analyze_images_local.py
"""

import os
import json
import sys
import time

try:
    from fer import FER
    import cv2
except ImportError:
    print("=" * 60)
    print("ç¼ºå°‘å¿…è¦ä¾èµ–ï¼Œè¯·å®‰è£…ï¼š")
    print("pip install fer opencv-python tensorflow")
    print("=" * 60)
    sys.exit(1)

from config import SAVE_CONFIG, EMOTION_CONFIG


def analyze_single_image(image_path, detector):
    """åˆ†æå•å¼ å›¾ç‰‡çš„æƒ…ç»ª"""
    
    if not os.path.exists(image_path):
        return {"error": f"å›¾ç‰‡ä¸å­˜åœ¨: {image_path}"}
    
    image = cv2.imread(image_path)
    if image is None:
        return {"error": "æ— æ³•è¯»å–å›¾ç‰‡"}
    
    results = detector.detect_emotions(image)
    
    if not results:
        return {"face_count": 0, "faces": [], "main_emotion": None}
    
    emotions_cn = {
        "happy": "å–œ",
        "angry": "æ€’",
        "sad": "å“€",
        "fear": "æƒ§",
        "surprise": "æƒŠ",
        "disgust": "åŒ",
        "neutral": "ä¸­æ€§"
    }
    
    all_faces = []
    for idx, face in enumerate(results):
        face_emotions = face["emotions"]
        emotions_cn_scores = {
            emotions_cn[k]: int(v * 100) for k, v in face_emotions.items()
        }
        main_emotion = emotions_cn[max(face_emotions, key=face_emotions.get)]
        
        all_faces.append({
            "face_id": idx + 1,
            "box": face["box"],
            "emotions": emotions_cn_scores,
            "main_emotion": main_emotion
        })
    
    return {
        "face_count": len(results),
        "faces": all_faces,
        "main_emotion": all_faces[0]["main_emotion"] if all_faces else None
    }


def get_all_images(base_path="./data/images"):
    """è·å–æ‰€æœ‰å·²ä¿å­˜çš„å›¾ç‰‡è·¯å¾„"""
    image_paths = []
    
    if not os.path.exists(base_path):
        return image_paths
    
    for root, dirs, files in os.walk(base_path):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp')):
                image_paths.append(os.path.join(root, file))
    
    return image_paths


def batch_analyze_images(image_paths, show_progress=True):
    """æ‰¹é‡åˆ†æå›¾ç‰‡æƒ…ç»ª"""
    
    print("æ­£åœ¨åˆå§‹åŒ–FERæ£€æµ‹å™¨...")
    detector = FER(mtcnn=True)
    
    results = []
    total = len(image_paths)
    face_found = 0
    
    for idx, path in enumerate(image_paths, 1):
        if show_progress and idx % 10 == 0:
            print(f"åˆ†æè¿›åº¦: {idx}/{total} ({idx*100//total}%)")
        
        analysis = analyze_single_image(path, detector)
        
        if analysis.get("face_count", 0) > 0:
            face_found += 1
        
        results.append({
            "image_path": path,
            "emotion_analysis": analysis
        })
    
    print(f"\nåˆ†æå®Œæˆï¼š{total} å¼ å›¾ç‰‡ï¼Œ{face_found} å¼ æ£€æµ‹åˆ°äººè„¸")
    return results


def get_emotion_statistics(analyzed_data):
    """ç»Ÿè®¡æƒ…ç»ªåˆ†å¸ƒ"""
    emotion_counts = {e: 0 for e in EMOTION_CONFIG["emotions"]}
    total_faces = 0
    
    for item in analyzed_data:
        analysis = item.get("emotion_analysis", {})
        faces = analysis.get("faces", [])
        
        for face in faces:
            main_emotion = face.get("main_emotion")
            if main_emotion and main_emotion in emotion_counts:
                emotion_counts[main_emotion] += 1
                total_faces += 1
    
    stats = {
        "total_images": len(analyzed_data),
        "total_faces": total_faces,
        "emotion_counts": emotion_counts,
        "emotion_percentages": {
            e: round(c / total_faces * 100, 2) if total_faces > 0 else 0
            for e, c in emotion_counts.items()
        }
    }
    
    return stats


def save_results(results, stats, output_dir="./data/analyzed"):
    """ä¿å­˜åˆ†æç»“æœ"""
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = int(time.time())
    
    results_file = os.path.join(output_dir, f"images_with_emotion_{timestamp}.json")
    with open(results_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜ï¼š{results_file}")
    
    stats_file = os.path.join(output_dir, f"image_stats_{timestamp}.json")
    with open(stats_file, "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    print(f"âœ… ç»Ÿè®¡æ•°æ®å·²ä¿å­˜ï¼š{stats_file}")
    
    return results_file, stats_file


def main():
    print("=" * 60)
    print("ğŸ–¼ï¸ æœ¬åœ°å›¾ç‰‡æƒ…ç»ªåˆ†æç¨‹åº")
    print("=" * 60)
    
    image_paths = get_all_images()
    
    if not image_paths:
        print("âŒ æœªæ‰¾åˆ°å¾…åˆ†æçš„å›¾ç‰‡")
        print("è¯·ç¡®ä¿ ./data/images/ ç›®å½•ä¸‹æœ‰å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")
    
    results = batch_analyze_images(image_paths, show_progress=True)
    
    stats = get_emotion_statistics(results)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æƒ…ç»ªåˆ†å¸ƒç»Ÿè®¡")
    print("=" * 60)
    print(f"æ€»å›¾ç‰‡æ•°ï¼š{stats['total_images']}")
    print(f"æ£€æµ‹åˆ°äººè„¸ï¼š{stats['total_faces']} ä¸ª")
    print("\næƒ…ç»ªåˆ†å¸ƒï¼š")
    for emotion, count in stats["emotion_counts"].items():
        pct = stats["emotion_percentages"][emotion]
        bar = "â–ˆ" * int(pct / 5) if pct > 0 else ""
        print(f"  {emotion}: {count:4d} ({pct:5.1f}%) {bar}")
    
    save_results(results, stats)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å›¾ç‰‡æƒ…ç»ªåˆ†æå®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
